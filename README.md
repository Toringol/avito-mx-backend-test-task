# avito-mx-backend-test-task

## Решение тестового задания avito Merchant Experience

[Ссылка на задание](https://github.com/avito-tech/mx-backend-trainee-assignment)

## Логика работы и архитектура

Проект выполнен с помощью чистой архитектуры, все независимые элементы отделены
друг от друга, что облегчает тестирование и дальнейшую разработку.
Логирование выполнено с помощью многоуровневого logrus логера, для запросов работает мидлвара.
Остальная часть проекта написала с помощью стандартных библиотек.

### Расположения элементов

- Модели: app/models
- Логика сервира: app/businessConnService/
- Файлы сборки контейнеров: build/
- Main файл: cmd/
- Конфигурация: config/
- Вспомогательные функции: tools/
- Документация: docs/

### Хэндлеры

- /loadProduct (post запрос на загрузку пачки экселек на добавление продуктов в базу)
Принимает поле seller_id и множество файлов products в виде form data
Возвращает task_id

- /getProduct (get запрос на получение эксельки продуктов по пользовательским данным)
Принимает поля seller_id, offer_id, name в виде json (все поля необязательные)
Возвращает excel file с продуктами совпадающими с запросом

- /getTaskState/{task_id:[0-9]+} (get запрос на просмотр состояния задачи(объяснение для чего ниже))
Принимает task_id в виде query params
Возвращает task_id и state в виде json (state может быть CREATED, IN PROGRESS и DONE)

- /getTaskStats/{task_id:[0-9]+} (get запрос на просмотр статистики задачи(объяснение также ниже))
Принимает task_id в виде query params
Возвращает task_id, products_created, products_updated, products_deleted, rows_with_errors в виде json

### Асинхронная работа

При загрузке пачки xlsx файлов на хендлер /loadProduct возращается айди задачи, по которой можно
потом следить за выполнением и при завершении загрузки посмотреть всю статистику. Для каждого файла
выполняется отдельная горутина, также для каждого листа в файле выполняется отдельная горутина, статистика
собирается асинхронно с каждого листа в файле. За обработку этой асинхронности отвечает taskManager, 
расположенный в папке app/businessConnService/delivery/taskManager. Он следит за 3 событиями с помощью каналов
(появление новой задачи, завершение задачи и остановка работы).

## Как запустить

- sudo docker-compose up --build (Сеть настроена на 172.20.0.0/16 и дефолтный 
ip контейнера будет 172.20.0.1, если по какой-то причине это не так, в config/config.yml
изменить DBHost на нужный).

При запуске данной команды запускаются два контейнера расположенные в build/, один для postgresql(
с стартовым скриптом init.sql для создания необходимых таблиц), второй для нашего сервиса.

## Документация

Swagger документация расположения в docs/swagger.yaml, там расположена документация на хэндлеры.
Остальная докумантация методов и неочевидных мест представлена в коде в виде комментариев.

## Teсты

- тесты на базу данных находятся в app/businessConnService/repository/memory_test.go (покрытие 67%)
- тесты на хэндлеры находятся в app/businessConnService/delivery/http/handlers_test.go (покрытие 73.4%)
- тесты на вспомогательные функции находятся в tools/convertXlsxRowToProductInfo_test.go (покрытие 96.9%)

## Нагрузочное тестирование

Нагрузочное тестирование было произведено с помощью postman, как и ручное тестирование при разработке, почему был
выбран postman ниже, для нагрузки были подготовлены файлы с 3 листами по 1000 продуктов, в каждом запросе было 8
таких файлов, всего выполнялось 4 параллельных запроса, серсис справляется за ~10 секунд с такой нагрузкой.

## О чем думал и почему не сделал

- Нагрузочное тестирование (хотелось сделать нормальное тестирование с помощью apache bench, но не понял как оправлять
сразу несколько multipart файлов с несколькими полями, тк в запросе еще должен быть seller_id, поэтому решил взять postman)
- Тестирование (хотелось протестировать все на 80+ процентов, но в логике работы базах данных не понял как тестировать rowsAffected, 
тк на запрос в базу возвращается структура result, из которой мы потом берем rowsAffected, в handlers не знаю как протестировать 
невалидный json.Marshall, точнее там уже выполняется маршалл для конкретной структуры, в которую уже не вставишь доп данные,
но что самое главное не особо понимаю как тестировать горутины из-за недостатка опыта, из идей было тестировать вызовы горутин и 
просто считать сколько их запустилось, и так смотреть ожидаемое поведение)
- Архитектура (думал о выделении в отдельный сервис task manager и общении с помощью grpc или на каждый запрос на загрузку продуктов,
делать новую запись в БД о запросе и данные, которые необходимо обработать, а task manager делает периодически запросы в эту
таблицу и смотрит не появились ли новые задачи и выполняет их, но боялся не успеть подать заявление, тк поздно узнал о стажировке)

## Впечатления

Задача отличная! Некоторые вещи лучше понял, а некоторые узучил, например, работу с excel.